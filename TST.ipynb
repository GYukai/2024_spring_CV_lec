{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "\n",
    "from vis import *\n",
    "from dataset_bjtu import *\n",
    "register_coco_instances(\"bjtu_train_washed\", {}, \"BJTU_washed/train.json\", \".\")\n",
    "register_coco_instances(\"bjtu_test_washed\", {}, \"BJTU_washed/test.json\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/18 23:30:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/18 23:30:54 d2.data.datasets.coco]: \u001b[0mLoaded 562 images in COCO format from BJTU_washed/train.json\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = DatasetCatalog.get(\"bjtu_train_washed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"RCTW_17/dsdl/dsdl_OCR_full/set-train/train_samples.json\", \"r\") as read_file:\n",
    "    bjtu = json.load(read_file)\n",
    "\n",
    "bjtu[\"samples\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': {'img_path': 'train_images/image_1.jpg',\n",
       "  'image_shape': [2448, 2448]},\n",
       " 'instances': [{'polygon': [[[1275.0, 1139.0],\n",
       "     [1483.0, 1131.0],\n",
       "     [1485.0, 1213.0],\n",
       "     [1277.0, 1220.0]]],\n",
       "   'text': '川·M',\n",
       "   'difficult': False},\n",
       "  {'polygon': [[[1242.0, 1220.0],\n",
       "     [1534.0, 1213.0],\n",
       "     [1535.0, 1293.0],\n",
       "     [1243.0, 1300.0]]],\n",
       "   'text': 'A07126',\n",
       "   'difficult': False},\n",
       "  {'polygon': [[[1187.0, 1359.0],\n",
       "     [1588.0, 1347.0],\n",
       "     [1593.0, 1511.0],\n",
       "     [1192.0, 1523.0]]],\n",
       "   'text': '大地四海',\n",
       "   'difficult': False},\n",
       "  {'polygon': [[[1211.0, 1500.0],\n",
       "     [1599.0, 1503.0],\n",
       "     [1599.0, 1600.0],\n",
       "     [1211.0, 1597.0]]],\n",
       "   'text': '电动车商城',\n",
       "   'difficult': False},\n",
       "  {'polygon': [[[1227.0, 1597.0],\n",
       "     [1610.0, 1602.0],\n",
       "     [1609.0, 1649.0],\n",
       "     [1226.0, 1644.0]]],\n",
       "   'text': '好品牌应有尽有',\n",
       "   'difficult': False},\n",
       "  {'polygon': [[[1236.0, 1640.0],\n",
       "     [1616.0, 1647.0],\n",
       "     [1616.0, 1678.0],\n",
       "     [1235.0, 1671.0]]],\n",
       "   'text': '资阳西门原松涛车站内',\n",
       "   'difficult': False},\n",
       "  {'polygon': [[[1244.0, 1675.0],\n",
       "     [1622.0, 1681.0],\n",
       "     [1621.0, 1704.0],\n",
       "     [1243.0, 1698.0]]],\n",
       "   'text': '###',\n",
       "   'difficult': True},\n",
       "  {'polygon': [[[1246.0, 1690.0],\n",
       "     [1614.0, 1698.0],\n",
       "     [1614.0, 1724.0],\n",
       "     [1246.0, 1716.0]]],\n",
       "   'text': '###',\n",
       "   'difficult': True},\n",
       "  {'polygon': [[[966.0, 463.0],\n",
       "     [1347.0, 398.0],\n",
       "     [1320.0, 507.0],\n",
       "     [942.0, 576.0]]],\n",
       "   'text': '玫瑰之约',\n",
       "   'difficult': False}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"RCTW_17/dsdl/dsdl_OCR_full/set-train/train_samples.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "data[\"samples\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'rctw_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m         dataset_dicts\u001b[38;5;241m.\u001b[39mappend(record)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset_dicts\n\u001b[0;32m---> 35\u001b[0m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrctw_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_rctw_dicts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRCTW_17/raw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrctw_train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset(thing_classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/mnt/data131/gyk/envs/lib/python3.8/site-packages/detectron2/data/catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m[name] \u001b[38;5;241m=\u001b[39m func\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'rctw_train' is already registered!"
     ]
    }
   ],
   "source": [
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "import cv2\n",
    "import os \n",
    "import tqdm\n",
    "\n",
    "def get_rctw_dicts(img_dir):\n",
    "    with open(\"RCTW_17/dsdl/dsdl_OCR_full/set-train/train_samples.json\", \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "    dataset_dicts = []\n",
    "    data = data[\"samples\"]\n",
    "    for idx, entry in tqdm.tqdm(enumerate(data)):\n",
    "        img_path = entry[\"image\"][\"img_path\"]\n",
    "        h, w = cv2.imread(os.path.join(\"RCTW_17/raw\",img_path)).shape[:2]\n",
    "        record = {}\n",
    "        record[\"file_name\"] = img_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = h\n",
    "        record[\"width\"] = w\n",
    "        annotations = []\n",
    "        for objs in entry[\"instances\"]:\n",
    "            polygon = objs[\"polygon\"][0]\n",
    "            xs = [point[0] for point in polygon]\n",
    "            ys = [point[1] for point in polygon]\n",
    "            x_min, x_max, y_min, y_max = min(xs), max(xs), min(ys), max(ys)\n",
    "            obj = {\n",
    "                \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"category_id\": 0,\n",
    "            }\n",
    "            annotations.append(obj)\n",
    "        record[\"annotations\"] = annotations\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "DatasetCatalog.register(\"rctw_train\", lambda: get_rctw_dicts(\"RCTW_17/raw\"))\n",
    "MetadataCatalog.get(\"rctw_train\").set(thing_classes=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8034it [03:37, 36.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets.coco import convert_to_coco_json\n",
    "import json\n",
    "convert_to_coco_json(\"rctw_train\", \"./rctw_train.json\",allow_cached=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bjtu_dicts(img_dir):\n",
    "    img_ext = ['jpg', 'png', 'jpeg', 'webp']\n",
    "    img_files=sorted([filename for ext in img_ext for filename in glob.glob(img_dir + '/**/*.' + ext,recursive=True) ])\n",
    "    json_files = sorted([filename for filename in glob.glob(img_dir + '/**/*.json',recursive=True) ])\n",
    "    dataset_dicts = []\n",
    "    for idx, (img_path, json_path) in enumerate(zip(img_files, json_files)):\n",
    "        assert img_path.split('/')[-1].split('.')[0] == json_path.split('/')[-1].split('.')[0] # json-img 1-1 correspondence\n",
    "        with open(json_path) as f:\n",
    "            imgs_anns = json.load(f)\n",
    "        record = {}\n",
    "        height, width = cv2.imread(img_path).shape[:2]\n",
    "        record[\"file_name\"] = img_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        annotations = []\n",
    "        \n",
    "        shapes = imgs_anns['shapes']\n",
    "        if len(shapes) != 1:\n",
    "            print(f\"{len(shapes)} shapes in {img_path}\")\n",
    "            continue\n",
    "        if shapes[0][\"shape_type\"] != \"rectangle\":\n",
    "            print(f\"{shapes[0]['shape_type']} shape_type in {img_path}\")\n",
    "            continue\n",
    "        label = shapes[0][\"label\"]\n",
    "        points = shapes[0][\"points\"]\n",
    "        x_min, x_max = int(min(points[0][0], points[1][0])), int(max(points[0][0], points[1][0]))\n",
    "        y_min, y_max = int(min(points[0][1], points[1][1])), int(max(points[0][1], points[1][1]))\n",
    "        obj = {\n",
    "            \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "            \"category_id\": label2id[label],\n",
    "        }\n",
    "        record[\"annotations\"] = [obj]\n",
    "        dataset_dicts.append(record)\n",
    "\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detectron2.data.datasets.load_coco_json(\"RCTW_17/dsdl/dsdl_OCR_full/set-train/train_samples.json\", \"RCTW_17/raw\", \"RCTW_train\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
